{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os, string\n",
    "import csv\n",
    "import pymongo\n",
    "import time\n",
    "import json \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract (Scrape) Data\n",
    "\n",
    "#### *Does not need to be loaded to pymongo* - can be scraped on the spot for the Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currentDirectory = os.path.dirname(__file__)\n",
    "# executable_path = {\"executable_path\": f\"{currentDirectory}\\chromedriver.exe\"}\n",
    "executable_path = {'executable_path': 'chromedriver.exe'} #notebook version\n",
    "browser = Browser('chrome', **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_sched_url = \"https://www.espn.com/nba/schedule/_/date/\"\n",
    "browser.visit(nba_sched_url)\n",
    "browser.html\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "sched_tables = soup.find('table', class_=\"schedule has-team-logos align-left\")\n",
    "schedules_sites = pd.read_html(sched_tables.prettify())\n",
    "schedules_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load - Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dump to mongo / Clean on the go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = \"mongodb://localhost:27017\"\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.nba\n",
    "# db.nba_players_stg.drop()\n",
    "# db.nba_news_live.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_reference_url = \"https://www.landofbasketball.com\"\n",
    "#Traverse to all players\n",
    "for letter in string.ascii_lowercase[:26]:\n",
    "    players_url = f\"https://www.landofbasketball.com/nba_players_index/letter_{letter}.htm\"\n",
    "    browser.visit(players_url)\n",
    "    browser.html\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    all_player_table = soup.find_all('div', class_=\"indice-items\")\n",
    "    for row in all_player_table:\n",
    "        player_d = {}\n",
    "        print(row.find('a')['href'], end='')\n",
    "        player_url = row.find('a')['href'].replace('..', base_reference_url)\n",
    "        tables = pd.read_html(player_url)\n",
    "        try_df = tables[1].set_index(0)\n",
    "        try_df.rename(columns={0: \"Key\", 1: \"Value\"}, inplace=True)\n",
    "        try_df = try_df.to_dict('index')\n",
    "        player_d['Name'] = tables[3][0][0].split(' Profile',1)[0]\n",
    "        player_d['Data'] = try_df\n",
    "        db.nba_players_stg.insert_one(player_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# result_dict['facts'] = list(db.mars_fact.find({}, {\"_id\": 0}))\n",
    "for a in db.nba_players_stg.find({}, {\"_id\": 0}).limit(2):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_news_url = \"https://apnews.com/NBA\"\n",
    "browser.visit(nba_news_url)\n",
    "browser.html\n",
    "# time.sleep(10)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "news_tables = soup.find_all('div', attrs={\"data-key\":\"feed-card-wire-story-with-image\"})\n",
    "# schedules_sites = pd.read_html(sched_tables.prettify())\n",
    "# schedules_sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in news_tables:\n",
    "    news_content = {}\n",
    "    news_content['headline'] = row.h1.text\n",
    "    news_content['content'] = row.p.text\n",
    "    print(f\"Loading {row.h1.text}....\")\n",
    "    db.nba_news_live.insert_one(news_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL For elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geojson_source = \"etl/gz_2010_us_050_00_500k.json\"\n",
    "# geojson_pd = pd.read_json(geojson_source)\n",
    "\n",
    "# json_file = \"etl/gz_2010_us_050_00_500k.json\"\n",
    "# customer_location_df = pd.read_json(json_file, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = \"etl/countypres_2000-2016.csv\"\n",
    "results_df = pd.read_csv(results_file, encoding=\"utf-8\")\n",
    "results_df.head()\n",
    "results_df.dropna(inplace=True)\n",
    "results_df.drop(columns=['office', 'version'],inplace=True)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.loc[results_df['county'].str.lower() ==\"Orange\".lower(),:]\n",
    "\n",
    "# Cast float to integer\n",
    "results_df.FIPS = results_df.FIPS.astype(int)\n",
    "results_df.candidatevotes = results_df.candidatevotes.astype(int)\n",
    "results_df.party = results_df.party.str.title()\n",
    "# Calculate percent won\n",
    "results_df[\"percentwon\"] = ((results_df.candidatevotes / results_df.totalvotes) * 100).map(\"{0:,.2f}\".format).astype(float)\n",
    "# results_df.percentwon = results_df.percentwon.astype(int)\n",
    "# Drop index\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Test results\n",
    "# results_df.loc[(results_df['county'].str.lower() ==\"Orange\".lower()) & (results_df['state'] == \"California\"),:].head(100)\n",
    "# results_df.head()\n",
    "# results_2016 = results_df.loc[(results_df.year == 2016) & (results_df['state'] == \"California\"),:]\n",
    "#results_2016 = results_df.loc[(results_df.year >= 2008) & (results_df.year <= 2016) & ((results_df.party == 'Republican') | (results_df.party == 'Democrat')),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_json(\"etl/processed.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEO JSON BIG SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "# geojson_source = \"etl/us-county-boundaries.geojson\" https://public.opendatasoft.com/explore/dataset/us-county-boundaries/export/?refine.stusab=CA\n",
    "# geojson_source = \"etl/gz_2010_us_050_00_500k.json\"\n",
    "# geojson_source = \"etl/ca-us-county-boundaries.csv.csv\"\n",
    "geojson_source = \"etl/us-county-boundaries.csv\"\n",
    "geojson_pd = pd.read_csv(geojson_source, delimiter=';')\n",
    "geojson_pd.dtypes\n",
    "geojson_pd = geojson_pd[['GEOID','Geo Shape']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEOJSON Small source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "# geojson_source = \"etl/us-county-boundaries.geojson\" https://public.opendatasoft.com/explore/dataset/us-county-boundaries/export/?refine.stusab=CA\n",
    "# geojson_source = \"etl/gz_2010_us_050_00_500k.json\"\n",
    "# geojson_source = \"etl/ca-us-county-boundaries.csv.csv\"\n",
    "geojson_source = \"etl/gz_2010_us_050_00_20m.json\"\n",
    "geojson_pd = pd.read_json(geojson_source, encoding='latin-1', lines=True)\n",
    "geojson_pd.rename(columns={\"geometry\": \"Geo Shape\"},inplace=True)\n",
    "# geojson_pd = geojson_pd[['Geometry']]\n",
    "# geojson_pd['FIPS'] = int(geojson_pd['properties']['GEO_ID'][-5:])\n",
    "geojson_pd['GEOID']  = geojson_pd.apply(lambda row: int(row.properties['GEO_ID'][-5:]), axis=1)\n",
    "# geojson_pd['properties'][0]['GEO_ID'] '0500000US01001'\n",
    "# int(geojson_pd['properties'][0]['GEO_ID'][-5:])\n",
    "# geojson_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-98c7d67694f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# geojson_source = \"etl/ca-us-county-boundaries.csv.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgeojson_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"etl/us_states.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgeojson_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeojson_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# geojson_pd.rename(columns={\"geometry\": \"Geo Shape\"},inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# geojson_pd = geojson_pd[['Geometry']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"frame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"series\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m             self.obj = DataFrame(\n\u001b[1;32m-> 1089\u001b[1;33m                 \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1090\u001b[0m             )\n\u001b[0;32m   1091\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "# https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "# geojson_source = \"etl/us-county-boundaries.geojson\" https://public.opendatasoft.com/explore/dataset/us-county-boundaries/export/?refine.stusab=CA\n",
    "# geojson_source = \"etl/gz_2010_us_050_00_500k.json\"\n",
    "# geojson_source = \"etl/ca-us-county-boundaries.csv.csv\"\n",
    "geojson_source = \"etl/us_states.json\"\n",
    "geojson_pd = pd.read_json(geojson_source, lines=True)\n",
    "# geojson_pd.rename(columns={\"geometry\": \"Geo Shape\"},inplace=True)\n",
    "# geojson_pd = geojson_pd[['Geometry']]\n",
    "# geojson_pd['FIPS'] = int(geojson_pd['properties']['GEO_ID'][-5:])\n",
    "# geojson_pd['GEOID']  = geojson_pd.apply(lambda row: int(row.properties['GEO_ID'][-5:]), axis=1)\n",
    "# geojson_pd['properties'][0]['GEO_ID'] '0500000US01001'\n",
    "# int(geojson_pd['properties'][0]['GEO_ID'][-5:])\n",
    "geojson_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geojson_pd\n",
    "# results_df\n",
    "def geo_merger(results_2016):\n",
    "    joined_df = pd.DataFrame();\n",
    "    joined_df = geojson_pd.merge(results_2016[['FIPS','year','state_po','county','candidate','party','candidatevotes','totalvotes','percentwon']].loc[(results_2016.party == 'Republican')], how=\"inner\", right_on='FIPS', left_on='GEOID');\n",
    "    joined_df = joined_df.merge(results_2016[['FIPS','candidate','party','candidatevotes','totalvotes','percentwon']].loc[(results_2016.party == 'Democrat')], how=\"inner\", right_on='FIPS', left_on='GEOID',suffixes=('_rep', '_dem'));\n",
    "    joined_df['winner'] = np.where(joined_df['candidatevotes_rep'] > joined_df['candidatevotes_dem'], 'red',  'blue');\n",
    "    return joined_df;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2008 = results_df.loc[(results_df.year == 2008) & ((results_df.party == 'Republican') | (results_df.party == 'Democrat')),:]\n",
    "results_2012 = results_df.loc[(results_df.year == 2012) & ((results_df.party == 'Republican') | (results_df.party == 'Democrat')),:]\n",
    "results_2016 = results_df.loc[(results_df.year == 2016) & ((results_df.party == 'Republican') | (results_df.party == 'Democrat')),:]\n",
    "merged_2008 = geo_merger(results_2008);\n",
    "merged_2012 = geo_merger(results_2012);\n",
    "merged_2016 = geo_merger(results_2016);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged = pd.concat([merged_2008, merged_2012, merged_2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_geojson(df, properties):\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "    for _, row in df.iterrows():\n",
    "        feature = {'type':'Feature',\n",
    "                   'properties':{}\n",
    "#                    'geometry':{}\n",
    "                  }\n",
    "        feature['geometry'] = row['Geo Shape'] #Use json.loads(row['Geo Shape']) if using the big source\n",
    "        for prop in properties:\n",
    "            feature['properties'][prop] = row[prop]\n",
    "        geojson['features'].append(feature)\n",
    "    return geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties = ['year', 'state_po', 'county', 'candidate_rep', 'party_rep', 'candidatevotes_rep', 'percentwon_rep', 'candidate_dem', 'party_dem', 'candidatevotes_dem', 'totalvotes_dem', 'percentwon_dem', 'winner']\n",
    "properties = ['year' ,'state_po', 'county', 'candidate_rep', 'party_rep', 'candidatevotes_rep', 'percentwon_rep', 'candidate_dem', 'party_dem', 'candidatevotes_dem', 'totalvotes_dem', 'percentwon_dem', 'winner']\n",
    "geojson = df_to_geojson(final_merged, properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = json.dumps(geojson)\n",
    "f = open(\"etl/processed.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()\n",
    "\n",
    "# output_filename = 'dataset.js'\n",
    "# with open(output_filename, 'wb') as output_file:\n",
    "#     output_file.write('var dataset = ')\n",
    "#     json.dump(geojson, output_file, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
